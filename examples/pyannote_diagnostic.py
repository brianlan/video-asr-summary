#!/usr/bin/env python3
"""
Diagnostic script to understand pyannote.audio model requirements and licensing.
"""

import os
import sys
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def check_pyannote_models():
    """Check what models pyannote speaker diarization actually uses."""
    print("ğŸ” Investigating pyannote.audio model requirements...")

    try:
        import pyannote.audio

        print(f"âœ… pyannote.audio version: {pyannote.audio.__version__}")

        # Try to load the pipeline and see what happens
        print("\nğŸ“‹ Attempting to load speaker-diarization-3.1 pipeline...")

        from pyannote.audio import Pipeline

        # Check if we have a token
        token = os.getenv("HUGGINGFACE_TOKEN")
        if not token:
            print("âŒ No HUGGINGFACE_TOKEN found in environment")
            return False

        print(f"âœ… Found HF token: {token[:8]}...")

        try:
            # This will show us what's actually required
            pipeline = Pipeline.from_pretrained(
                "pyannote/speaker-diarization-3.1", use_auth_token=token
            )
            print("âœ… Pipeline loaded successfully!")

            # Check what models it contains
            print("\nğŸ”§ Pipeline components:")
            if hasattr(pipeline, "_models"):
                for name, model in pipeline._models.items():
                    print(f"  - {name}: {model}")

            return True

        except Exception as e:
            print(f"âŒ Pipeline loading failed: {e}")
            print(f"Error type: {type(e).__name__}")

            # Check if it's a specific license issue
            if (
                "gated" in str(e).lower()
                or "license" in str(e).lower()
                or "access" in str(e).lower()
            ):
                print("\nğŸ”‘ This appears to be a license/access issue.")
                print(
                    "The speaker-diarization-3.1 pipeline likely uses multiple models:"
                )
                print("  1. Speaker segmentation model (to find speech segments)")
                print("  2. Speaker embedding model (to identify speakers)")
                print("  3. Clustering/diarization logic")
                print("\nYou may need to accept licenses for ALL component models:")
                print(
                    "  - Go to: https://huggingface.co/pyannote/speaker-diarization-3.1"
                )
                print("  - Check which models it depends on")
                print("  - Accept licenses for each dependency")

            return False

    except ImportError as e:
        print(f"âŒ Import error: {e}")
        return False
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        return False


def explain_segmentation_difference():
    """Explain the difference between Whisper and pyannote segmentation."""
    print("\n" + "=" * 60)
    print("ğŸ“š SEGMENTATION TYPES EXPLAINED")
    print("=" * 60)

    print(
        """
ğŸ¤ WHISPER SEGMENTATION (Content-based):
   Purpose: Split audio by SPEECH CONTENT
   Criteria: Pauses, sentence boundaries, topics
   Output:  "WHAT was said WHEN"
   
   Example:
   [0-30s]: "ç¬¬ä¸€ç« ,è¡Œä¸º,The Behaviour,æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½..."
   [30-58s]: "åœ¨å‰å‡ å°æ—¶åˆ°å‡ å¤©å†…,æ˜¯ä»€ä¹ˆæ”¹å˜äº†ç¥ç»ç³»ç»Ÿ..."

ğŸ‘¥ PYANNOTE SEGMENTATION (Speaker-based):  
   Purpose: Split audio by SPEAKER IDENTITY
   Criteria: Voice characteristics, acoustic features
   Output:  "WHO was speaking WHEN"
   
   Example:
   [0-25s]:  SPEAKER_00 (Professor)
   [25-45s]: SPEAKER_01 (Student) 
   [45-70s]: SPEAKER_00 (Professor)

ğŸ”— INTEGRATION (The Magic):
   Combine both to get: "WHO said WHAT WHEN"
   
   Result:
   [0-25s]:  SPEAKER_00: "ç¬¬ä¸€ç« ,è¡Œä¸º,The Behaviour..."
   [25-30s]: SPEAKER_01: "åœ¨å‰å‡ å°æ—¶åˆ°å‡ å¤©å†…..."
   [30-45s]: SPEAKER_01: "æ˜¯ä»€ä¹ˆæ”¹å˜äº†ç¥ç»ç³»ç»Ÿ..."
"""
    )

    print("ğŸ’¡ Why we need pyannote's segmentation:")
    print("   - Whisper doesn't know about voice characteristics")
    print("   - pyannote doesn't understand speech content")
    print("   - Together they create speaker-attributed transcripts")


def test_with_simpler_model():
    """Try using a different, possibly non-gated model."""
    print("\n" + "=" * 60)
    print("ğŸ§ª TESTING ALTERNATIVE APPROACHES")
    print("=" * 60)

    try:
        from pyannote.audio import Pipeline

        token = os.getenv("HUGGINGFACE_TOKEN")
        if not token:
            print("âŒ No token available for testing")
            return False

        # Try different model versions
        models_to_try = [
            "pyannote/speaker-diarization-3.0",  # Older version
            "pyannote/speaker-diarization",  # Default version
        ]

        for model_name in models_to_try:
            print(f"\nğŸ”„ Trying {model_name}...")
            try:
                pipeline = Pipeline.from_pretrained(model_name, use_auth_token=token)
                print(f"âœ… {model_name} loaded successfully!")
                return True
            except Exception as e:
                print(f"âŒ {model_name} failed: {e}")

        return False

    except Exception as e:
        print(f"âŒ Alternative testing failed: {e}")
        return False


def main():
    """Main diagnostic function."""
    print("ğŸ”¬ pyannote.audio Model Diagnostic Tool")
    print("=" * 50)

    # Explain the conceptual difference first
    explain_segmentation_difference()

    # Check model requirements
    success = check_pyannote_models()

    if not success:
        print("\nğŸ”„ Trying alternative models...")
        test_with_simpler_model()

    print("\n" + "=" * 60)
    print("ğŸ“‹ SUMMARY")
    print("=" * 60)
    print(
        """
Your understanding is mostly correct! Here's the key insight:

âœ… Whisper gives us CONTENT segmentation (what was said when)
âœ… pyannote gives us SPEAKER segmentation (who was speaking when)  
âœ… We need BOTH to create speaker-attributed transcripts

The segmentation-3.0 license you accepted might be for a component model.
The speaker-diarization-3.1 pipeline likely uses multiple models internally.

Next steps:
1. Visit: https://huggingface.co/pyannote/speaker-diarization-3.1  
2. Accept any additional license agreements
3. Check which component models need licenses
"""
    )


if __name__ == "__main__":
    main()
